package com.softbank.back.infra.service;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.softbank.back.infra.model.*;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;

import java.io.*;
import java.nio.file.*;
import java.time.LocalDateTime;
import java.util.*;
import java.util.concurrent.*;

@Slf4j
@Service
public class TerraformService {

    @Value("${terraform.base.path:src/main/resources/terraform}")
    private String terraformBasePath;

    @Value("${terraform.workspace.path:./terraform-workspaces}")
    private String workspacePath;

    @Value("${terraform.max.concurrent.operations:1}")
    private int maxConcurrentOperations;

    @Value("${terraform.max.queue.size:10}")
    private int maxQueueSize;

    // ì„¸ì…˜ë³„ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
    private final Map<String, SessionContext> sessions = new ConcurrentHashMap<>();
    private final ObjectMapper objectMapper = new ObjectMapper();
    private final TerraformBackendService backendService;

    // ë™ì‹œ ì‹¤í–‰ ì œí•œì„ ìœ„í•œ Semaphore
    private Semaphore executionSemaphore;

    // ì „ìš© ìŠ¤ë ˆë“œ í’€ (ì œí•œëœ í¬ê¸°)
    private ExecutorService terraformExecutor;

    // ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… ì¶”ì 
    private final Map<String, CompletableFuture<?>> pendingTasks = new ConcurrentHashMap<>();

    public TerraformService(TerraformBackendService backendService) {
        this.backendService = backendService;
    }

    @jakarta.annotation.PostConstruct
    public void initializeExecutor() {
        // ë™ì‹œ ì‹¤í–‰ ì œí•œ Semaphore ì´ˆê¸°í™”
        this.executionSemaphore = new Semaphore(maxConcurrentOperations, true); // fair mode

        // ì „ìš© ìŠ¤ë ˆë“œ í’€ ìƒì„± (ìµœëŒ€ í í¬ê¸° ì œí•œ)
        BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue<>(maxQueueSize);
        this.terraformExecutor = new ThreadPoolExecutor(
            1, // core pool size
            maxConcurrentOperations, // maximum pool size
            60L, TimeUnit.SECONDS, // keep alive time
            workQueue,
            new ThreadFactory() {
                private final java.util.concurrent.atomic.AtomicInteger counter = new java.util.concurrent.atomic.AtomicInteger(0);
                @Override
                @SuppressWarnings("NullableProblems")
                public Thread newThread(Runnable r) {
                    Thread t = new Thread(r);
                    t.setName("terraform-executor-" + counter.incrementAndGet());
                    t.setDaemon(false);
                    return t;
                }
            },
            new ThreadPoolExecutor.AbortPolicy() // íê°€ ê°€ë“ ì°¨ë©´ ì˜ˆì™¸ ë°œìƒ
        );

        log.info("ğŸš€ Terraform Executor initialized: maxConcurrent={}, maxQueueSize={}",
            maxConcurrentOperations, maxQueueSize);

        // ì„¸ì…˜ ë³µêµ¬ëŠ” ë³„ë„ë¡œ ì‹¤í–‰
        recoverSessions();
    }

    @jakarta.annotation.PreDestroy
    public void shutdownExecutor() {
        log.info("ğŸ›‘ Shutting down Terraform Executor...");
        if (terraformExecutor != null) {
            terraformExecutor.shutdown();
            try {
                if (!terraformExecutor.awaitTermination(30, TimeUnit.SECONDS)) {
                    terraformExecutor.shutdownNow();
                }
            } catch (InterruptedException e) {
                terraformExecutor.shutdownNow();
                Thread.currentThread().interrupt();
            }
        }
    }

    /**
     * â­ ì„œë²„ ì‹œì‘ ì‹œ ì„¸ì…˜ ë³µêµ¬
     */
    @jakarta.annotation.PostConstruct
    public void recoverSessions() {
        log.info("ğŸ”„ Starting session recovery...");

        try {
            Path workspaceRoot = Paths.get(workspacePath);
            if (!Files.exists(workspaceRoot)) {
                log.info("No workspace directory found. Skipping recovery.");
                return;
            }

            int recoveredCount = 0;
            int failedCount = 0;

            try (var stream = Files.list(workspaceRoot)) {
                var sessionDirs = stream.filter(Files::isDirectory).toList();

                for (Path sessionDir : sessionDirs) {
                    try {
                        Path progressFile = sessionDir.resolve(".progress.json");

                        if (Files.exists(progressFile)) {
                            String sessionId = sessionDir.getFileName().toString();
                            log.info("Found session data for: {}", sessionId);

                            SessionContext context = SessionContext.loadFromFile(progressFile);
                            context.setSessionId(sessionId);
                            context.setWorkingDirectory(sessionDir.toAbsolutePath().toString());

                            // ì§„í–‰ ì¤‘ì´ë˜ ì‘ì—…ì€ FAILEDë¡œ ë³€ê²½
                            if (context.getStatus() == InfraStatus.APPLYING ||
                                context.getStatus() == InfraStatus.PLANNING ||
                                context.getStatus() == InfraStatus.INIT) {
                                context.updateStatus(InfraStatus.FAILED,
                                    context.getProgressPercentage(),
                                    "Server restarted during provisioning. You can retry or destroy the resources.");
                            }

                            sessions.put(sessionId, context);
                            recoveredCount++;
                            log.info("âœ… Recovered session: {} (status: {})", sessionId, context.getStatus());
                        }
                    } catch (Exception e) {
                        failedCount++;
                        log.error("âŒ Failed to recover session from {}", sessionDir, e);
                    }
                }
            }

            log.info("ğŸ‰ Session recovery completed: {} recovered, {} failed", recoveredCount, failedCount);

        } catch (Exception e) {
            log.error("âŒ Session recovery failed", e);
        }
    }

    /**
     * FR-01: ë¹„ë™ê¸° ì¸í”„ë¼ ë°°í¬ ì‹œì‘ (íƒ€ì„ì•„ì›ƒ ë° ìë™ ë¡¤ë°± í¬í•¨)
     * PUT ë©”ì„œë“œë¡œ í˜¸ì¶œ - ê¸°ì¡´ ì¸í”„ë¼ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒì„±
     * â­ Semaphoreë¥¼ ì‚¬ìš©í•œ ë™ì‹œ ì‹¤í–‰ ì œí•œ ì¶”ê°€
     */
    public CompletableFuture<InfraResponse> applyInfrastructure(TerraformRequest request) {
        String sessionId = request.getSessionId();

        // ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ í™•ì¸ ë˜ëŠ” ìƒì„±
        SessionContext context = sessions.computeIfAbsent(sessionId, id -> {
            String sessionDir = createSessionWorkspace(id);
            return new SessionContext(id, sessionDir);
        });

        // ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…ì´ ìˆëŠ”ì§€ í™•ì¸
        if (context.getCurrentTask() != null && !context.getCurrentTask().isDone()) {
            log.warn("Session {} already has a task in progress", sessionId);
            throw new IllegalStateException("Provisioning already in progress for session: " + sessionId);
        }

        context.setRequest(request);

        // ëŒ€ê¸°ì—´ ìƒíƒœ í™•ì¸
        int availablePermits = executionSemaphore.availablePermits();
        int queuedTasks = pendingTasks.size();

        if (availablePermits == 0) {
            log.warn("â³ No available execution slots. Session {} will be queued. Current queue: {}/{}",
                sessionId, queuedTasks, maxQueueSize);
            context.updateStatus(InfraStatus.INIT, 0,
                String.format("Waiting in queue... (%d/%d tasks ahead)", queuedTasks, maxConcurrentOperations));
        } else {
            context.updateStatus(InfraStatus.INIT, 0, "Initializing Terraform...");
        }

        // ë¹„ë™ê¸° ì‘ì—… ì‹œì‘ (ì „ìš© ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©)
        CompletableFuture<InfraResponse> task = CompletableFuture.supplyAsync(() -> {
            // Semaphore íšë“ ì‹œë„
            boolean acquired = false;
            try {
                log.info("ğŸ”’ Session {} waiting for execution permit...", sessionId);
                context.updateStatus(InfraStatus.INIT, 0, "Waiting for available resources...");

                // ìµœëŒ€ 30ì´ˆ ëŒ€ê¸° (ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ì‹œ ì˜ˆì™¸)
                acquired = executionSemaphore.tryAcquire(30, TimeUnit.SECONDS);

                if (!acquired) {
                    log.error("âŒ Session {} failed to acquire execution permit within 30 seconds", sessionId);
                    throw new RuntimeException("Server is too busy. Please try again later.");
                }

                log.info("âœ… Session {} acquired execution permit. Starting terraform apply...", sessionId);
                context.updateStatus(InfraStatus.INIT, 0, "Starting Terraform execution...");

                return executeTerrformApply(context);
            } catch (InterruptedException e) {
                log.error("âŒ Session {} interrupted while waiting for permit", sessionId, e);
                Thread.currentThread().interrupt();
                context.updateStatus(InfraStatus.FAILED, 0, "Interrupted while waiting");
                throw new RuntimeException("Execution interrupted", e);
            } catch (Exception e) {
                log.error("Terraform apply failed for session {}", sessionId, e);
                context.updateStatus(InfraStatus.FAILED, 0, "Error: " + e.getMessage());
                throw new RuntimeException("Terraform apply failed", e);
            } finally {
                // Semaphore ë°˜í™˜
                if (acquired) {
                    executionSemaphore.release();
                    log.info("ğŸ”“ Session {} released execution permit. Available: {}/{}",
                        sessionId, executionSemaphore.availablePermits(), maxConcurrentOperations);
                }
                // ëŒ€ê¸° ëª©ë¡ì—ì„œ ì œê±°
                pendingTasks.remove(sessionId);
            }
        }, terraformExecutor) // ì „ìš© ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©
        .orTimeout(10, java.util.concurrent.TimeUnit.MINUTES)
        .exceptionally(ex -> {
            // íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ì—ëŸ¬ ë°œìƒ ì‹œ ìë™ ë¡¤ë°±
            if (ex.getCause() instanceof java.util.concurrent.TimeoutException) {
                log.error("â±ï¸ Terraform apply timeout (10 minutes) for session: {}", sessionId);
                context.updateStatus(InfraStatus.FAILED, 0, "Timeout: Terraform apply exceeded 10 minutes");
                executeAutoRollback(context);
            } else if (ex.getCause() instanceof RejectedExecutionException) {
                log.error("âŒ Task queue is full for session: {}", sessionId);
                context.updateStatus(InfraStatus.FAILED, 0, "Server queue is full. Please try again later.");
            } else {
                log.error("âŒ Terraform apply error for session: {}", sessionId, ex);
                executeAutoRollback(context);
            }

            throw new RuntimeException("Provisioning failed and rolled back", ex);
        });

        // ëŒ€ê¸° ëª©ë¡ì— ì¶”ê°€
        pendingTasks.put(sessionId, task);
        context.setCurrentTask(task.thenAccept(r -> {}));
        return task;
    }

    /**
     * FR-04: ë¦¬ì†ŒìŠ¤ íŒŒê´´ (ê°œì„ : ì„¸ì…˜ì´ ì—†ì–´ë„ ì‘ë™)
     * â­ Semaphoreë¥¼ ì‚¬ìš©í•œ ë™ì‹œ ì‹¤í–‰ ì œí•œ ì¶”ê°€
     */
    public CompletableFuture<String> destroyInfrastructure(String sessionId) {
        SessionContext context = sessions.get(sessionId);

        // â­ ì„¸ì…˜ì´ ì—†ìœ¼ë©´ ë³µêµ¬ ì‹œë„
        if (context == null) {
            log.warn("Session {} not found in memory. Attempting to recover or create temporary session...", sessionId);

            // 1. workspace ë””ë ‰í† ë¦¬ í™•ì¸
            Path sessionDir = Paths.get(workspacePath, sessionId);
            if (Files.exists(sessionDir)) {
                // ë””ë ‰í† ë¦¬ê°€ ìˆìœ¼ë©´ ì„ì‹œ ì„¸ì…˜ ìƒì„±
                log.info("Found workspace directory for session: {}. Creating temporary session.", sessionId);
                context = new SessionContext(sessionId, sessionDir.toAbsolutePath().toString());
                context.updateStatus(InfraStatus.DESTROYING, 0, "Recovered session for destruction");
                sessions.put(sessionId, context);
            } else {
                // ë””ë ‰í† ë¦¬ë„ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± (Terraform workspaceì—ì„œ stateë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ)
                log.info("No workspace directory found. Creating new workspace for session: {}", sessionId);
                String newSessionDir = createSessionWorkspace(sessionId);
                context = new SessionContext(sessionId, newSessionDir);
                context.updateStatus(InfraStatus.DESTROYING, 0, "Created workspace to destroy remote resources");
                sessions.put(sessionId, context);
            }
        }

        // ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…ì´ ìˆëŠ”ì§€ í™•ì¸
        if (context.getCurrentTask() != null && !context.getCurrentTask().isDone()) {
            throw new IllegalStateException("Another operation is in progress for session: " + sessionId);
        }

        // ëŒ€ê¸°ì—´ ìƒíƒœ í™•ì¸
        int availablePermits = executionSemaphore.availablePermits();
        int queuedTasks = pendingTasks.size();

        if (availablePermits == 0) {
            log.warn("â³ No available execution slots. Session {} destroy will be queued. Current queue: {}/{}",
                sessionId, queuedTasks, maxQueueSize);
            context.updateStatus(InfraStatus.DESTROYING, 0,
                String.format("Waiting in queue... (%d/%d tasks ahead)", queuedTasks, maxConcurrentOperations));
        } else {
            context.updateStatus(InfraStatus.DESTROYING, 0, "Starting terraform destroy...");
        }

        final SessionContext finalContext = context;

        CompletableFuture<String> task = CompletableFuture.supplyAsync(() -> {
            // Semaphore íšë“ ì‹œë„
            boolean acquired = false;
            try {
                log.info("ğŸ”’ Session {} waiting for execution permit (destroy)...", sessionId);
                finalContext.updateStatus(InfraStatus.DESTROYING, 0, "Waiting for available resources...");

                // ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
                acquired = executionSemaphore.tryAcquire(30, TimeUnit.SECONDS);

                if (!acquired) {
                    log.error("âŒ Session {} failed to acquire execution permit within 30 seconds", sessionId);
                    throw new RuntimeException("Server is too busy. Please try again later.");
                }

                log.info("âœ… Session {} acquired execution permit. Starting terraform destroy...", sessionId);
                finalContext.updateStatus(InfraStatus.DESTROYING, 0, "Destroying infrastructure...");

                return executeTerraformDestroy(finalContext);
            } catch (InterruptedException e) {
                log.error("âŒ Session {} interrupted while waiting for permit", sessionId, e);
                Thread.currentThread().interrupt();
                finalContext.updateStatus(InfraStatus.FAILED, 0, "Interrupted while waiting");
                throw new RuntimeException("Execution interrupted", e);
            } catch (Exception e) {
                log.error("Terraform destroy failed for session {}", sessionId, e);
                finalContext.updateStatus(InfraStatus.FAILED, 0, "Destroy failed: " + e.getMessage());
                throw new RuntimeException("Terraform destroy failed", e);
            } finally {
                // Semaphore ë°˜í™˜
                if (acquired) {
                    executionSemaphore.release();
                    log.info("ğŸ”“ Session {} released execution permit. Available: {}/{}",
                        sessionId, executionSemaphore.availablePermits(), maxConcurrentOperations);
                }
                // ëŒ€ê¸° ëª©ë¡ì—ì„œ ì œê±°
                pendingTasks.remove(sessionId);
            }
        }, terraformExecutor) // ì „ìš© ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©
        .exceptionally(ex -> {
            if (ex.getCause() instanceof RejectedExecutionException) {
                log.error("âŒ Task queue is full for session: {}", sessionId);
                finalContext.updateStatus(InfraStatus.FAILED, 0, "Server queue is full. Please try again later.");
            }
            throw new RuntimeException("Destroy failed", ex);
        });

        // ëŒ€ê¸° ëª©ë¡ì— ì¶”ê°€
        pendingTasks.put(sessionId, task);
        finalContext.setCurrentTask(task.thenAccept(r -> {}));
        return task;
    }

    /**
     * FR-02: ì‹¤ì‹œê°„ ìƒíƒœ ì¡°íšŒ
     */
    public ProvisioningLog getStatus(String sessionId) {
        SessionContext context = sessions.get(sessionId);
        if (context == null) {
            return new ProvisioningLog(sessionId, InfraStatus.INIT, 0, "No session found", LocalDateTime.now());
        }

        return new ProvisioningLog(
                sessionId,
                context.getStatus(),
                context.getProgressPercentage(),
                context.getLatestLog(),
                context.getLastUpdated()
        );
    }

    /**
     * ì„œë²„ ë¦¬ì†ŒìŠ¤ ìƒíƒœ ì¡°íšŒ (ë™ì‹œ ì‹¤í–‰ ì œí•œ ì •ë³´)
     */
    public Map<String, Object> getServerResourceStatus() {
        Map<String, Object> status = new HashMap<>();

        // ì‹¤í–‰ ìŠ¬ë¡¯ ì •ë³´
        int availableSlots = executionSemaphore.availablePermits();
        int totalSlots = maxConcurrentOperations;
        int activeSlots = totalSlots - availableSlots;

        status.put("totalExecutionSlots", totalSlots);
        status.put("availableSlots", availableSlots);
        status.put("activeSlots", activeSlots);
        status.put("queuedTasks", pendingTasks.size());
        status.put("maxQueueSize", maxQueueSize);

        // ìŠ¤ë ˆë“œ í’€ ì •ë³´
        if (terraformExecutor instanceof ThreadPoolExecutor) {
            ThreadPoolExecutor executor = (ThreadPoolExecutor) terraformExecutor;
            status.put("poolSize", executor.getPoolSize());
            status.put("activeThreads", executor.getActiveCount());
            status.put("completedTasks", executor.getCompletedTaskCount());
            status.put("queueSize", executor.getQueue().size());
        }

        // í™œì„± ì„¸ì…˜ ì •ë³´
        List<Map<String, Object>> activeSessions = new ArrayList<>();
        for (Map.Entry<String, SessionContext> entry : sessions.entrySet()) {
            SessionContext ctx = entry.getValue();
            if (ctx.getCurrentTask() != null && !ctx.getCurrentTask().isDone()) {
                Map<String, Object> sessionInfo = new HashMap<>();
                sessionInfo.put("sessionId", entry.getKey());
                sessionInfo.put("status", ctx.getStatus());
                sessionInfo.put("progress", ctx.getProgressPercentage());
                activeSessions.add(sessionInfo);
            }
        }
        status.put("activeSessions", activeSessions);

        return status;
    }

    /**
     * FR-03: ì¸í”„ë¼ ì •ë³´ ì¡°íšŒ (Terraform outputs)
     */
    public InfraResponse getInfrastructureInfo(String sessionId) throws Exception {
        SessionContext context = sessions.get(sessionId);
        if (context == null) {
            throw new IllegalStateException("No infrastructure found for session: " + sessionId);
        }

        Map<String, Object> outputs = parseTerraformOutputs(context.getWorkingDirectory());

        return new InfraResponse(
                sessionId,
                context.getStatus(),
                outputs,
                "Infrastructure information retrieved"
        );
    }

    /**
     * â­ Terraform graph ìƒì„± (DOT í˜•ì‹)
     * terraform graph ëª…ë ¹ì–´ ì¶œë ¥ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜
     */
    public String getTerraformGraph(String sessionId) throws Exception {
        SessionContext context = sessions.get(sessionId);
        if (context == null) {
            throw new IllegalStateException("No infrastructure found for session: " + sessionId);
        }

        String workDir = context.getWorkingDirectory();

        try {
            // terraform graph ì‹¤í–‰ (ë¡œê·¸ ì¶œë ¥ ì—†ì´)
            String graph = runCommandSilent(workDir, "terraform", "graph");
            log.debug("Generated terraform graph for session: {}", sessionId);
            return graph;
        } catch (Exception e) {
            log.error("Failed to generate terraform graph for session: {}", sessionId, e);
            throw new RuntimeException("Failed to generate terraform graph", e);
        }
    }

    /**
     * Terraform apply ì‹¤í–‰
     */
    private InfraResponse executeTerrformApply(SessionContext context) throws Exception {
        String workDir = context.getWorkingDirectory();
        String sessionId = context.getSessionId();
        TerraformRequest request = context.getRequest();

        // 0. â­ Backend ë¦¬ì†ŒìŠ¤ í™•ì¸ ë° ìƒì„± (S3/DynamoDB)
        context.updateStatus(InfraStatus.INIT, 5, "Ensuring Terraform backend resources exist...");
        try {
            backendService.ensureBackendResourcesExist();
            log.info("âœ… Backend resources are ready for session: {}", sessionId);
        } catch (Exception e) {
            log.error("Failed to initialize backend resources", e);
            throw new RuntimeException("Backend initialization failed: " + e.getMessage(), e);
        }

        // 1. Terraform íŒŒì¼ ë³µì‚¬
        context.updateStatus(InfraStatus.INIT, 10, "Copying terraform files...");
        copyTerraformFiles(workDir);

        // 2. tfvars íŒŒì¼ ìƒì„±
        context.updateStatus(InfraStatus.INIT, 15, "Creating terraform.tfvars...");
        createTfvarsFile(workDir, request);

        // 3. â­ Terraform init (Backend ì—°ê²°)
        context.updateStatus(InfraStatus.INIT, 20, "Running terraform init...");
        try {
            runCommand(workDir, "terraform", "init", "-input=false");
            log.info("âœ… Terraform initialized for session: {}", sessionId);
        } catch (Exception e) {
            log.error("Terraform init failed for session: {}", sessionId, e);
            throw new RuntimeException("Terraform init failed. Backend resources may not be accessible.", e);
        }

        // 4. â­ Workspace ìƒì„± ë˜ëŠ” ì„ íƒ
        context.updateStatus(InfraStatus.INIT, 25, "Setting up terraform workspace...");
        try {
            ensureWorkspaceExists(workDir, sessionId);
            log.info("âœ… Workspace '{}' is ready", sessionId);
        } catch (Exception e) {
            log.error("Workspace setup failed for session: {}", sessionId, e);
            throw new RuntimeException("Workspace setup failed: " + e.getMessage(), e);
        }

        // 5. Terraform plan (State Lock ì—ëŸ¬ ì‹œ ìë™ ì¬ì‹œë„)
        context.updateStatus(InfraStatus.PLANNING, 40, "Running terraform plan...");
        try {
            runCommand(workDir, "terraform", "plan", "-out=tfplan", "-input=false");
        } catch (RuntimeException e) {
            if (e.getMessage() != null && e.getMessage().contains("Error acquiring the state lock")) {
                log.warn("ğŸ”’ State lock detected during plan. Attempting to force unlock...");
                handleStateLockError(context, workDir, e);
                // ì¬ì‹œë„
                runCommand(workDir, "terraform", "plan", "-out=tfplan", "-input=false");
            } else {
                throw e;
            }
        }

        // 6. Terraform apply (State Lock ì—ëŸ¬ ì‹œ ìë™ ì¬ì‹œë„)
        context.updateStatus(InfraStatus.APPLYING, 60, "Running terraform apply...");
        try {
            runCommand(workDir, "terraform", "apply", "-input=false", "-auto-approve", "tfplan");
        } catch (RuntimeException e) {
            if (e.getMessage() != null && e.getMessage().contains("Error acquiring the state lock")) {
                log.warn("ğŸ”’ State lock detected during apply. Attempting to force unlock...");
                handleStateLockError(context, workDir, e);
                // ì¬ì‹œë„
                runCommand(workDir, "terraform", "apply", "-input=false", "-auto-approve", "tfplan");
            } else {
                throw e;
            }
        }

        // 7. Outputs íŒŒì‹±
        context.updateStatus(InfraStatus.COMPLETE, 100, "Infrastructure provisioning completed!");
        Map<String, Object> outputs = parseTerraformOutputs(workDir);

        return new InfraResponse(
                context.getSessionId(),
                InfraStatus.COMPLETE,
                outputs,
                "Infrastructure successfully provisioned"
        );
    }

    /**
     * â­ Terraform Workspace ìƒì„± ë˜ëŠ” ì„ íƒ
     * ê° ì„¸ì…˜ì€ ë…ë¦½ì ì¸ workspaceë¥¼ ì‚¬ìš©í•˜ì—¬ stateë¥¼ ê²©ë¦¬í•©ë‹ˆë‹¤.
     */
    private void ensureWorkspaceExists(String workDir, String sessionId) throws IOException, InterruptedException {
        // 1. í˜„ì¬ workspace ëª©ë¡ í™•ì¸
        String workspaceList = runCommand(workDir, "terraform", "workspace", "list");
        log.debug("Current workspaces:\n{}", workspaceList);

        // 2. sessionId workspaceê°€ ìˆëŠ”ì§€ í™•ì¸
        boolean workspaceExists = workspaceList.contains(sessionId);

        if (workspaceExists) {
            // Workspaceê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì„ íƒ
            log.info("Selecting existing workspace: {}", sessionId);
            runCommand(workDir, "terraform", "workspace", "select", sessionId);
        } else {
            // Workspaceê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            log.info("Creating new workspace: {}", sessionId);
            runCommand(workDir, "terraform", "workspace", "new", sessionId);
        }

        // 3. í˜„ì¬ workspace í™•ì¸
        String currentWorkspace = runCommand(workDir, "terraform", "workspace", "show").trim();
        log.info("Current workspace: {}", currentWorkspace);

        if (!currentWorkspace.equals(sessionId)) {
            throw new IllegalStateException(
                    String.format("Failed to switch to workspace '%s'. Current workspace: '%s'",
                            sessionId, currentWorkspace)
            );
        }
    }

    /**
     * â­ FR-01: ìë™ ë¡¤ë°± ì‹¤í–‰ (ë¶€ë¶„ ìƒì„± ì‹¤íŒ¨ ì‹œ)
     * ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ì—¬ ë©”ì¸ ìŠ¤ë ˆë“œë¥¼ ë¸”ë¡í•˜ì§€ ì•ŠìŒ
     */
    private void executeAutoRollback(SessionContext context) {
        CompletableFuture.runAsync(() -> {
            try {
                log.warn("ğŸ”„ Auto-rollback initiated for session: {}", context.getSessionId());
                context.updateStatus(InfraStatus.DESTROYING, 0, "Auto-rollback: Cleaning up partial resources...");

                String workDir = context.getWorkingDirectory();
                String sessionId = context.getSessionId();

                // 1. Workspace ì„ íƒ ì‹œë„
                try {
                    runCommand(workDir, "terraform", "workspace", "select", sessionId);
                    log.info("âœ“ Workspace selected: {}", sessionId);
                } catch (Exception e) {
                    log.warn("Workspace selection failed (may not exist): {}", e.getMessage());
                }

                // 2. Terraform destroy ì‹¤í–‰ (ë¶€ë¶„ ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ ì œê±°)
                try {
                    context.updateStatus(InfraStatus.DESTROYING, 30, "Auto-rollback: Running terraform destroy...");
                    runCommand(workDir, "terraform", "destroy", "-auto-approve", "-input=false");
                    log.info("âœ“ Resources destroyed");
                } catch (Exception e) {
                    log.error("âŒ Terraform destroy failed during rollback: {}", e.getMessage());
                    context.updateStatus(InfraStatus.FAILED, 0,
                        "Auto-rollback failed: " + e.getMessage() + " (Manual cleanup may be required)");
                    return;
                }

                // 3. Workspace ì •ë¦¬
                try {
                    context.updateStatus(InfraStatus.DESTROYING, 80, "Auto-rollback: Cleaning up workspace...");
                    runCommand(workDir, "terraform", "workspace", "select", "default");
                    runCommand(workDir, "terraform", "workspace", "delete", sessionId);
                    log.info("âœ“ Workspace deleted: {}", sessionId);
                } catch (Exception e) {
                    log.warn("Workspace cleanup failed: {}", e.getMessage());
                }

                // 4. ë¡œì»¬ íŒŒì¼ ì‚­ì œ
                deleteDirectory(new File(workDir));

                // 5. ì„¸ì…˜ ì œê±°
                sessions.remove(sessionId);

                context.updateStatus(InfraStatus.FAILED, 100,
                    "Provisioning failed. All resources have been rolled back successfully.");
                log.info("âœ… Auto-rollback completed for session: {}", sessionId);

            } catch (Exception e) {
                log.error("âŒ Critical error during auto-rollback for session: {}",
                    context.getSessionId(), e);
                context.updateStatus(InfraStatus.FAILED, 0,
                    "Auto-rollback critical error: " + e.getMessage() + " (URGENT: Manual cleanup required!)");
            }
        });
    }

    /**
     * Terraform destroy ì‹¤í–‰
     */
    private String executeTerraformDestroy(SessionContext context) throws Exception {
        String workDir = context.getWorkingDirectory();
        String sessionId = context.getSessionId();

        // 1. Workspace ì„ íƒ
        context.updateStatus(InfraStatus.DESTROYING, 10, "Selecting workspace...");
        try {
            runCommand(workDir, "terraform", "workspace", "select", sessionId);
        } catch (Exception e) {
            log.warn("Failed to select workspace {}, it may not exist", sessionId);
        }

        // 2. Terraform destroy ì‹¤í–‰ (State Lock ì—ëŸ¬ ì‹œ ìë™ ì¬ì‹œë„)
        context.updateStatus(InfraStatus.DESTROYING, 30, "Running terraform destroy...");
        try {
            runCommand(workDir, "terraform", "destroy", "-auto-approve", "-input=false");
        } catch (RuntimeException e) {
            // â­ State Lock ì—ëŸ¬ ê°ì§€
            if (e.getMessage() != null && e.getMessage().contains("Error acquiring the state lock")) {
                log.warn("ğŸ”’ State lock detected. Attempting to force unlock...");
                handleStateLockError(context, workDir, e);
                // ì¬ì‹œë„
                context.updateStatus(InfraStatus.DESTROYING, 40, "Retrying terraform destroy...");
                runCommand(workDir, "terraform", "destroy", "-auto-approve", "-input=false");
            } else {
                throw e; // Lock ì—ëŸ¬ê°€ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
            }
        }

        // 3. Workspace ì‚­ì œ (ì„ íƒì‚¬í•­)
        context.updateStatus(InfraStatus.DESTROYING, 80, "Cleaning up workspace...");
        try {
            // default workspaceë¡œ ì „í™˜ í›„ ì‚­ì œ
            runCommand(workDir, "terraform", "workspace", "select", "default");
            runCommand(workDir, "terraform", "workspace", "delete", sessionId);
            log.info("Workspace '{}' deleted", sessionId);
        } catch (Exception e) {
            log.warn("Failed to delete workspace {}: {}", sessionId, e.getMessage());
        }

        context.updateStatus(InfraStatus.COMPLETE, 100, "Infrastructure destroyed successfully");

        // ì„¸ì…˜ ì œê±°
        sessions.remove(sessionId);

        // ì‘ì—… ë””ë ‰í† ë¦¬ ì‚­ì œ
        deleteDirectory(new File(workDir));

        return "Infrastructure destroyed successfully";
    }

    /**
     * ì„¸ì…˜ë³„ ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
     */
    private String createSessionWorkspace(String sessionId) {
        try {
            Path sessionPath = Paths.get(workspacePath, sessionId);
            Files.createDirectories(sessionPath);
            return sessionPath.toAbsolutePath().toString();
        } catch (IOException e) {
            throw new RuntimeException("Failed to create workspace for session: " + sessionId, e);
        }
    }

    /**
     * Terraform íŒŒì¼ë“¤ì„ ì„¸ì…˜ ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
     * JAR íŒŒì¼ ë‚´ë¶€ì˜ classpath ë¦¬ì†ŒìŠ¤ë¥¼ ì§€ì›í•©ë‹ˆë‹¤
     */
    private void copyTerraformFiles(String targetDir) throws IOException {
        Path targetPath = Paths.get(targetDir);

        // JAR íŒŒì¼ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
        boolean runningFromJar = getClass().getResource("/" + terraformBasePath.replace("src/main/resources/", "")) == null;

        if (runningFromJar || !Paths.get(terraformBasePath).toFile().exists()) {
            // JARì—ì„œ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ìƒëŒ€ ê²½ë¡œë¡œ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°, classpathì—ì„œ ë³µì‚¬
            log.info("Copying Terraform files from classpath (running from JAR)...");
            copyFromClasspath(targetPath);
        } else {
            // ê°œë°œ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì§ì ‘ ë³µì‚¬
            log.info("Copying Terraform files from filesystem (development mode)...");
            copyFromFilesystem(targetPath);
        }

        log.info("âœ… Terraform files copied to: {}", targetDir);
    }

    /**
     * classpathì—ì„œ Terraform íŒŒì¼ ë³µì‚¬ (JAR ì‹¤í–‰ ì‹œ)
     */
    private void copyFromClasspath(Path targetPath) throws IOException {
        String[] terraformFiles = {
            "terraform/backend.tf",
            "terraform/cloudwatch.tf",
            "terraform/dynamodb.tf",
            "terraform/ec2.tf",
            "terraform/iam.tf",
            "terraform/lambda.tf",
            "terraform/main.tf",
            "terraform/outputs.tf",
            "terraform/provider.tf",
            "terraform/s3.tf",
            "terraform/sns.tf",
            "terraform/variables.tf",
            "terraform/vpc.tf",
            "terraform/lambda/alarm_processor.py",
            "terraform/scripts/bootstrap-backend.sh"
        };

        for (String resourcePath : terraformFiles) {
            try (InputStream inputStream = getClass().getClassLoader().getResourceAsStream(resourcePath)) {
                if (inputStream == null) {
                    log.warn("Resource not found: {}", resourcePath);
                    continue;
                }

                // íŒŒì¼ ê²½ë¡œì—ì„œ 'terraform/' ì œê±°í•˜ê³  ëŒ€ìƒ ê²½ë¡œ ìƒì„±
                String relativePath = resourcePath.replace("terraform/", "");
                Path destFile = targetPath.resolve(relativePath);
                Files.createDirectories(destFile.getParent());
                Files.copy(inputStream, destFile, StandardCopyOption.REPLACE_EXISTING);

                log.debug("Copied: {} -> {}", resourcePath, destFile);
            }
        }
    }

    /**
     * íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ Terraform íŒŒì¼ ë³µì‚¬ (ê°œë°œ í™˜ê²½)
     */
    private void copyFromFilesystem(Path targetPath) throws IOException {
        Path sourcePath = Paths.get(terraformBasePath);

        // â­ í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ í™•ì¸
        validateRequiredTerraformFiles(sourcePath);

        try (var stream = Files.walk(sourcePath)) {
            stream.filter(source -> !Files.isDirectory(source))
                    .filter(source -> source.toString().endsWith(".tf") ||
                                    source.toString().endsWith(".py") ||
                                    source.toString().endsWith(".sh"))
                    .forEach(source -> {
                        try {
                            Path dest = targetPath.resolve(sourcePath.relativize(source));
                            Files.createDirectories(dest.getParent());
                            Files.copy(source, dest, StandardCopyOption.REPLACE_EXISTING);
                        } catch (IOException e) {
                            throw new UncheckedIOException(e);
                        }
                    });
        }
    }

    /**
     * â­ í•„ìˆ˜ Terraform íŒŒì¼ ì¡´ì¬ í™•ì¸
     */
    private void validateRequiredTerraformFiles(Path sourcePath) throws FileNotFoundException {
        String[] requiredFiles = {
                "provider.tf",
                "variables.tf",
                "backend.tf",
                "vpc.tf",
                "ec2.tf",
                "lambda/alarm_processor.py"
        };

        for (String file : requiredFiles) {
            Path filePath = sourcePath.resolve(file);
            if (!Files.exists(filePath)) {
                log.error("âŒ Required Terraform file not found: {}", filePath);
                throw new FileNotFoundException(
                        "Required Terraform file not found: " + file +
                        ". Please check the terraform directory structure.");
            }
        }

        log.debug("âœ… All required Terraform files exist");
    }

    /**
     * terraform.tfvars íŒŒì¼ ìƒì„±
     */
    private void createTfvarsFile(String workDir, TerraformRequest request) throws IOException {
        StringBuilder tfvars = new StringBuilder();
        tfvars.append(String.format("session_id = \"%s\"%n", request.getSessionId()));
        tfvars.append(String.format("aws_region = \"%s\"%n", request.getAwsRegion()));
        tfvars.append(String.format("project_name = \"%s\"%n", request.getProjectName()));
        tfvars.append(String.format("environment = \"%s\"%n", request.getEnvironment()));
        tfvars.append(String.format("ec2_instance_type = \"%s\"%n", request.getEc2InstanceType()));

        if (request.getEc2KeyName() != null && !request.getEc2KeyName().isEmpty()) {
            tfvars.append(String.format("ec2_key_name = \"%s\"%n", request.getEc2KeyName()));
        }

        if (request.getAlertEmail() != null && !request.getAlertEmail().isEmpty()) {
            tfvars.append(String.format("alert_email = \"%s\"%n", request.getAlertEmail()));
        }

        tfvars.append(String.format("cpu_warning_threshold = %d%n", request.getCpuWarningThreshold()));
        tfvars.append(String.format("cpu_critical_threshold = %d%n", request.getCpuCriticalThreshold()));
        tfvars.append(String.format("error_rate_warning_threshold = %d%n", request.getErrorRateWarningThreshold()));
        tfvars.append(String.format("error_rate_critical_threshold = %d%n", request.getErrorRateCriticalThreshold()));
        tfvars.append(String.format("latency_warning_threshold = %d%n", request.getLatencyWarningThreshold()));
        tfvars.append(String.format("latency_critical_threshold = %d%n", request.getLatencyCriticalThreshold()));

        Path tfvarsPath = Paths.get(workDir, "terraform.tfvars");
        Files.writeString(tfvarsPath, tfvars.toString());
    }

    /**
     * Terraform outputs íŒŒì‹± (ì•ˆì „í•œ ì—ëŸ¬ ì²˜ë¦¬)
     */
    private Map<String, Object> parseTerraformOutputs(String workDir) {
        try {
            String outputJson = runCommand(workDir, "terraform", "output", "-json");

            if (outputJson.trim().isEmpty()) {
                log.warn("âš ï¸  Terraform outputs are empty for workDir: {}", workDir);
                return new HashMap<>();
            }

            try {
                @SuppressWarnings("unchecked")
                Map<String, Map<String, Object>> rawOutputs =
                        objectMapper.readValue(outputJson, Map.class);

                Map<String, Object> outputs = new HashMap<>();
                rawOutputs.forEach((key, value) -> {
                    if (value != null && value.containsKey("value")) {
                        outputs.put(key, value.get("value"));
                    }
                });

                log.info("âœ… Parsed {} Terraform outputs", outputs.size());
                return outputs;

            } catch (com.fasterxml.jackson.core.JsonProcessingException e) {
                log.error("âŒ Failed to parse Terraform outputs JSON", e);
                log.error("   Raw output: {}", outputJson);
                log.error("   Returning empty outputs map");
                return new HashMap<>();
            }

        } catch (Exception e) {
            log.error("âŒ Failed to get Terraform outputs from workDir: {}", workDir, e);
            log.error("   Infrastructure may be provisioned, but outputs cannot be retrieved");
            return new HashMap<>();
        }
    }

    /**
     * ëª…ë ¹ì–´ ì‹¤í–‰
     */
    private String runCommand(String workDir, String... command) throws IOException, InterruptedException {
        ProcessBuilder pb = new ProcessBuilder(command);
        pb.directory(new File(workDir));
        pb.redirectErrorStream(true);

        Process process = pb.start();

        StringBuilder output = new StringBuilder();
        try (BufferedReader reader = new BufferedReader(new InputStreamReader(process.getInputStream()))) {
            String line;
            while ((line = reader.readLine()) != null) {
                output.append(line).append("\n");
                log.info("[Terraform] {}", line);
            }
        }

        int exitCode = process.waitFor();
        if (exitCode != 0) {
            throw new RuntimeException("Command failed with exit code " + exitCode + ": " + output);
        }

        return output.toString();
    }

    /**
     * â­ ëª…ë ¹ì–´ ì‹¤í–‰ (ë¡œê·¸ ì¶œë ¥ ì—†ìŒ - graph ìƒì„±ìš©)
     */
    private String runCommandSilent(String workDir, String... command) throws IOException, InterruptedException {
        ProcessBuilder pb = new ProcessBuilder(command);
        pb.directory(new File(workDir));
        pb.redirectErrorStream(true);

        Process process = pb.start();

        StringBuilder output = new StringBuilder();
        try (BufferedReader reader = new BufferedReader(new InputStreamReader(process.getInputStream()))) {
            String line;
            while ((line = reader.readLine()) != null) {
                output.append(line).append("\n");
            }
        }

        int exitCode = process.waitFor();
        if (exitCode != 0) {
            throw new RuntimeException("Command failed with exit code " + exitCode + ": " + output);
        }

        return output.toString();
    }

    /**
     * â­ State Lock ì—ëŸ¬ ê³µí†µ ì²˜ë¦¬
     */
    private void handleStateLockError(SessionContext context, String workDir, RuntimeException e) {
        String lockId = extractLockId(e.getMessage());
        if (lockId != null) {
            try {
                log.info("Forcing unlock with Lock ID: {}", lockId);
                context.updateStatus(context.getStatus(),
                    context.getProgressPercentage(),
                    "Detected state lock. Forcing unlock...");

                runCommand(workDir, "terraform", "force-unlock", "-force", lockId);
                log.info("âœ… Lock released successfully");

                context.updateStatus(context.getStatus(),
                    context.getProgressPercentage(),
                    "Lock released. Retrying...");
            } catch (Exception unlockError) {
                log.error("Failed to force unlock: {}", unlockError.getMessage());
                throw e; // ì›ë˜ ì—ëŸ¬ ì¬ë°œìƒ
            }
        } else {
            log.error("Could not extract Lock ID from error message");
            throw e;
        }
    }

    /**
     * â­ Terraform ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ Lock ID ì¶”ì¶œ
     */
    private String extractLockId(String errorMessage) {
        try {
            // "ID:        198e8aeb-21d9-5621-bc64-e70cecc4dffb" íŒ¨í„´ ì°¾ê¸°
            java.util.regex.Pattern pattern = java.util.regex.Pattern.compile("ID:\\s+([a-f0-9-]+)");
            java.util.regex.Matcher matcher = pattern.matcher(errorMessage);
            if (matcher.find()) {
                return matcher.group(1);
            }
        } catch (Exception e) {
            log.error("Failed to extract Lock ID", e);
        }
        return null;
    }

    /**
     * ë””ë ‰í† ë¦¬ ì‚­ì œ
     */
    private void deleteDirectory(File directory) {
        if (directory.exists()) {
            File[] files = directory.listFiles();
            if (files != null) {
                for (File file : files) {
                    if (file.isDirectory()) {
                        deleteDirectory(file);
                    } else {
                        file.delete();
                    }
                }
            }
            directory.delete();
        }
    }

    /**
     * ëª¨ë“  ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ (ê´€ë¦¬ìš©)
     */
    public List<ProvisioningLog> getAllSessions() {
        return sessions.values().stream()
                .map(ctx -> new ProvisioningLog(
                        ctx.getSessionId(),
                        ctx.getStatus(),
                        ctx.getProgressPercentage(),
                        ctx.getLatestLog(),
                        ctx.getLastUpdated()
                ))
                .toList();
    }

    /**
     * â­ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ (í”„ë¡ íŠ¸ì—”ë“œ APIìš©)
     */
    public SessionContext getSessionContext(String sessionId) {
        return sessions.get(sessionId);
    }

    /**
     * â­ Graceful Shutdown: ì„œë²„ ì¢…ë£Œ ì‹œ ëª¨ë“  ì„¸ì…˜ ìƒíƒœ ì €ì¥
     */
    @jakarta.annotation.PreDestroy
    public void shutdown() {
        log.info("ğŸ›‘ Graceful shutdown initiated...");

        if (sessions.isEmpty()) {
            log.info("No active sessions to save");
            return;
        }

        // ëª¨ë“  ì„¸ì…˜ ìƒíƒœ ì €ì¥
        sessions.forEach((sessionId, context) -> {
            try {
                context.saveToFile();
                log.info("âœ… Saved progress for session: {}", sessionId);
            } catch (Exception e) {
                log.error("âŒ Failed to save progress for session: {}", sessionId, e);
            }
        });

        // ì‹¤í–‰ ì¤‘ì¸ Task ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
        sessions.values().stream()
                .filter(ctx -> ctx.getCurrentTask() != null && !ctx.getCurrentTask().isDone())
                .forEach(ctx -> {
                    try {
                        log.info("â³ Waiting for task to complete: {}", ctx.getSessionId());
                        ctx.getCurrentTask().get(30, java.util.concurrent.TimeUnit.SECONDS);
                        log.info("âœ… Task completed: {}", ctx.getSessionId());
                    } catch (java.util.concurrent.TimeoutException e) {
                        log.warn("â±ï¸ Task timeout for session: {}", ctx.getSessionId());
                    } catch (Exception e) {
                        log.error("âŒ Error waiting for task: {}", ctx.getSessionId(), e);
                    }
                });

        log.info("âœ… Graceful shutdown completed. Saved {} sessions", sessions.size());
    }
}